{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hQfaQ9tP0BMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries: using Tensorflow framework to train the model"
      ],
      "metadata": {
        "id": "d8Z6F1420p8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n"
      ],
      "metadata": {
        "id": "sRoa75SC0ICI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the data set from my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EtTvFeIZ6lKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9005f8b8-9f1c-4a17-c5aa-f04a130748fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing: \n",
        "In this section the following actions were executed. \n",
        "\n",
        "1.   Rename each class of image: rename the images using the three given classes: Bed, Sofa, Chair. \n",
        "2.   create a new folder\n",
        "\n",
        "1.   Resize the images: resize the images for fine tuned model parameters\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rfcLtE83ZJ9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_path = '/content/drive/MyDrive/NneamakaProjects/Data for test/Sofa'\n",
        "\n",
        "prefix = 'Sofa_'\n",
        "count = 1\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.jpg'):\n",
        "        #old_name = os.path.join(folder_path, filename)\n",
        "        new_name = prefix + str(count) + '.jpg'\n",
        "        count += 1\n",
        "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_name))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "5WlX1sBKKbMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/NneamakaProjects/Data for test/Chair'\n",
        "\n",
        "prefix = 'Chair_'\n",
        "count = 1\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.jpg'):\n",
        "        #old_name = os.path.join(folder_path, filename)\n",
        "        new_name = prefix + str(count) + '.jpg'\n",
        "        count += 1\n",
        "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_name))\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "bWlJM0-hKfBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_path = '/content/drive/MyDrive/NneamakaProjects/Data for test/Bed'\n",
        "\n",
        "prefix = 'Bed_'\n",
        "count = 1\n",
        "for filename in os.listdir(folder_path):\n",
        "  if filename.endswith('.jpg'):\n",
        "        #old_name = os.path.join(folder_path, filename)\n",
        "        new_name = prefix + str(count) + '.jpg'\n",
        "        count += 1\n",
        "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_name))\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "-GC0HU5nKd3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_images(input_dir, output_dir, size):\n",
        "    \"\"\"\n",
        "    Resizes all images in input_dir to size and saves them in output_dir.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Loop over all files in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        # Only process image files\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Load the image\n",
        "            image = Image.open(os.path.join(input_dir, filename))\n",
        "            # Resize the image\n",
        "            resized_image = image.resize(size)\n",
        "            # Save the resized image to the output directory\n",
        "            resized_image.save(os.path.join(output_dir, filename))\n"
      ],
      "metadata": {
        "id": "4kKcpt0FMHG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/drive/MyDrive/NneamakaProjects/Train'\n",
        "output_dir = '/content/drive/MyDrive/NneamakaProjects/train_r'\n",
        "size = (256, 256)  # target size of the images\n",
        "\n",
        "resize_images(input_dir, output_dir, size)\n"
      ],
      "metadata": {
        "id": "K03qeFtrMG0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/drive/MyDrive/NneamakaProjects/test'\n",
        "output_dir = '/content/drive/MyDrive/NneamakaProjects/test_r'\n",
        "size = (256, 256)  # target size of the images\n",
        "\n",
        "resize_images(input_dir, output_dir, size)"
      ],
      "metadata": {
        "id": "_zj6sXnJSQB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training:\n",
        "This section includes the following actions:\n",
        "\n",
        "1.   Generate the model\n",
        "2.   Train the model using fit_generator method\n",
        "\n",
        "1.   Evaluate method using evaluate_generator method\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YEVx-X27c8bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/NneamakaProjects/train_r',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/NneamakaProjects/test_r',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI4rK9NCSrI5",
        "outputId": "55f35dd7-1cf8-42ff-d01f-f045ad026535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 240 images belonging to 3 classes.\n",
            "Found 60 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "model.save('/content/drive/MyDrive/NneamakaProjects')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XqhRRWoSq9T",
        "outputId": "4f94dd3c-64b3-4188-c131-65f4f0b55a78"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=10,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBka5mUFSq25",
        "outputId": "d3b9644d-a146-456e-eb93-b56e2fc00ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-c13f041cecc9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 8/10 [=======================>......] - ETA: 11s - loss: 0.7865 - accuracy: 0.6750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 52s 5s/step - loss: 0.7865 - accuracy: 0.6750 - val_loss: 0.5864 - val_accuracy: 0.7833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate_generator(validation_generator, steps=15)\n",
        "print('test acc:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiNn59fKgS-E",
        "outputId": "32ef4e99-1f1e-4267-9cd7-d14ac7c14901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-78-9764bdf5222c>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  test_loss, test_acc = model.evaluate_generator(validation_generator, steps=15)\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test acc: 0.699999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build an API:\n",
        "\n",
        "The kind of API implemented below is the FAST API. It functions thus:\n",
        "\n",
        "1.   Receives an input item- image\n",
        "2.   predicts a label based on the class of label the model was train on. It should retuen an output label of either - Sofa, Chair, or Bed.\n",
        "\n"
      ],
      "metadata": {
        "id": "iFxSjYNm0bnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uvicorn\n",
        "!pip install FastAPI\n",
        "!pip install python-multipart\n"
      ],
      "metadata": {
        "id": "g-hNuhyuSqvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5fda99-9dd6-4378-a4d3-4f8c97fd397f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/dist-packages (0.20.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.8/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: FastAPI in /usr/local/lib/python3.8/dist-packages (0.92.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from FastAPI) (1.10.5)\n",
            "Requirement already satisfied: starlette<0.26.0,>=0.25.0 in /usr/local/lib/python3.8/dist-packages (from FastAPI) (0.25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->FastAPI) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette<0.26.0,>=0.25.0->FastAPI) (3.6.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette<0.26.0,>=0.25.0->FastAPI) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette<0.26.0,>=0.25.0->FastAPI) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from python-multipart) (1.15.0)\n",
            "Building wheels for collected packages: python-multipart\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=c1e7c6933f660628e3121cf7da0d97827cfcabf17329fda25edb207fda36c495\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built python-multipart\n",
            "Installing collected packages: python-multipart\n",
            "Successfully installed python-multipart-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained image classification model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/NneamakaProjects')\n",
        "\n",
        "# Define the FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Define the endpoint for image classification\n",
        "@app.post(\"/predict\")\n",
        "async def predict(image: UploadFile = File(...)):\n",
        "    # Load the image file\n",
        "    data = await image.read()\n",
        "    img = Image.open(BytesIO(data))\n",
        "    \n",
        "    # Preprocess the image\n",
        "    img = img.resize((256, 256))\n",
        "    img = np.array(img)\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    \n",
        "    # Make a prediction\n",
        "    prediction = model.predict(img)\n",
        "    label = np.argmax(prediction, axis=1)[0]\n",
        "    \n",
        "    # Return the predicted label\n",
        "    if label == 0:\n",
        "        return {\"label\": \"Bed\"}\n",
        "    elif label == 1:\n",
        "        return {\"label\": \"Chair\"}\n",
        "    else:\n",
        "        return {\"label\": \"Sofa\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "7EUzpioZSqpJ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dk9siVGDzsd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}